{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, List\n",
    "import os\n",
    "import functools\n",
    "import pickle\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from data import get_factor_data, build_factor_data, get_factor_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halflifes = [21, 63, 126, 252]\n",
    "factor_data = build_factor_data(halflifes=halflifes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today_date = datetime.today().date()\n",
    "print(today_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "factor_data = build_factor_data_cache(halflifes=[63, 126, 252], read_cache=True)\n",
    "\n",
    "date_latest = factor_data.indexes['date'].max()\n",
    "date_today = pd.Timestamp(datetime.today().date())\n",
    "\n",
    "# factor_data.indexes['date'].max() < datetime.today().date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_factor_data(factor_data: xr.Dataset) -> bool:\n",
    "    date_latest = factor_data.indexes['date'].max()\n",
    "    return date_latest >= date_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_pickle(obj: Any, path: str) -> None:\n",
    "#     with open(path, 'wb') as f:\n",
    "#         pickle.dump(obj, f, protocol=-1)\n",
    "        \n",
    "# def read_pickle(path: str) -> Any:\n",
    "#     with open(path, 'rb') as f:\n",
    "#         return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt_dir = 'cache'\n",
    "ttt_file = 'data.pkl'\n",
    "\n",
    "os.path.join(ttt_dir, ttt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_factor_data_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_factor_data_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_decorator(func: Callable) -> Callable:\n",
    "    \"\"\"A decorator that caches function results to a Zarr file and Pickle file.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(asset: List, read_cache: bool = True, write_cache: bool = True, cache_path: str = \"cache\", use_pickle: bool = False, **kwargs) -> Any:\n",
    "        # Ensure cache directory exists\n",
    "        os.makedirs(cache_path, exist_ok=True)\n",
    "        \n",
    "        # Define cache file paths\n",
    "        pickle_cache_file = os.path.join(cache_path, \"market_data.pkl\")\n",
    "        \n",
    "        # Attempt to read from cache\n",
    "        if read_cache:\n",
    "            if use_pickle and os.path.exists(pickle_cache_file):\n",
    "                with open(pickle_cache_file, \"rb\") as f:\n",
    "                    return pickle.load(f)\n",
    "            elif os.path.exists(zarr_cache_file):\n",
    "                return xr.open_zarr(zarr_cache_file)\n",
    "        \n",
    "        # Call the original function\n",
    "        result = func(asset, **kwargs)\n",
    "        \n",
    "        # Write result to cache\n",
    "        if write_cache:\n",
    "            if use_pickle:\n",
    "                with open(pickle_cache_file, \"wb\") as f:\n",
    "                    pickle.dump(result, f)\n",
    "            else:\n",
    "                result.to_zarr(zarr_cache_file, mode=\"w\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(factor_data, 'factor_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "factor_data.to_zarr('factor_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cache_decorator(func: Callable) -> Callable:\n",
    "    \"\"\"A decorator that caches function results to a Zarr file.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(asset: List, read_cache: bool = True, write_cache: bool = True, cache_path: str = \"cache\", **kwargs) -> Any:\n",
    "        # Ensure cache directory exists\n",
    "        os.makedirs(cache_path, exist_ok=True)\n",
    "        \n",
    "        # Define cache file path\n",
    "        cache_file = os.path.join(cache_path, \"market_data.zarr\")\n",
    "        \n",
    "        # Attempt to read from cache\n",
    "        if read_cache and os.path.exists(cache_file):\n",
    "            return xr.open_zarr(cache_file)\n",
    "        \n",
    "        # Call the original function\n",
    "        result = func(asset, **kwargs)\n",
    "        \n",
    "        # Write result to cache\n",
    "        if write_cache:\n",
    "            result.to_zarr(cache_file, mode=\"w\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@cache_decorator\n",
    "def get_market_data(asset: List) -> xr.Dataset:\n",
    "    \"\"\"Simulate fetching market data for a list of assets.\"\"\"\n",
    "    time = np.arange(\"2023-01-01\", \"2023-01-10\", dtype=\"datetime64[D]\")\n",
    "    prices = np.random.rand(len(time), len(asset))\n",
    "    return xr.Dataset({\"price\": (\"time\", \"asset\", prices)}, coords={\"time\": (\"time\", time), \"asset\": (\"asset\", asset)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "assets = [\"AAPL\", \"GOOG\", \"MSFT\"]\n",
    "data = get_market_data(assets, read_cache=True, write_cache=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
