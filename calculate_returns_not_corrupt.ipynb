{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "xr.set_options(keep_attrs=True,\n",
    "               display_expand_data=False)\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from util import xr_pct_change, safe_reindex\n",
    "from data import get_factor_master, get_portfolios\n",
    "from stats import get_volatility_set, get_correlation_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out(df):\n",
    "    if isinstance(df, xr.DataArray):\n",
    "        df = df.to_pandas()\n",
    "    if isinstance(df, xr.Dataset):\n",
    "        df = df.to_pandas()\n",
    "    df.sort_index(ascending=False).to_clipboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data(ticker, field_name, cache=None):\n",
    "    # TODO: Check cache first\n",
    "    # cache.columns.get_level_values(1)\n",
    "    return yf.download(ticker)[field_name]\n",
    "\n",
    "\n",
    "def get_yahoo_data_set(tickers, field_name, asset_names=None):\n",
    "    if asset_names is None:\n",
    "        asset_names = tickers\n",
    "    return (pd.DataFrame({asset_name: get_yahoo_data(ticker, field_name) \n",
    "                         for asset_name, ticker in zip(asset_names, tickers)})\n",
    "            .rename_axis(index='date', columns='factor_name'))\n",
    "\n",
    "\n",
    "def fill_returns(df):\n",
    "    return df.ffill()\n",
    "\n",
    "\n",
    "def get_business_days(df, factor_names):\n",
    "    return df[factor_names].dropna(how='any').index\n",
    "\n",
    "\n",
    "def align_dates(df, business_day_factors):\n",
    "    dates_raw = df.index\n",
    "    dates_business = get_business_days(df, business_day_factors)\n",
    "    dates_union = dates_raw.union(dates_business)\n",
    "    return (df\n",
    "            .reindex(dates_union)\n",
    "            .pipe(fill_returns)\n",
    "            .loc[dates_business])\n",
    "\n",
    "\n",
    "def calculate_returns(cret, diffusion_type):\n",
    "    match diffusion_type:\n",
    "        case 'lognormal':\n",
    "            return cret.pct_change().mul(10_000)\n",
    "        case 'normal':\n",
    "            return cret.diff().mul(100)\n",
    "        # case 'normal10':\n",
    "        #     return cret.diff().div(10)\n",
    "        case _:\n",
    "            raise ValueError(f'Unsupported diffusion_type of {diffusion_type} for {cret.name}')\n",
    "        # case nan:\n",
    "        #     raise ValueError(f'No diffusion_type provided for {cret.name}')\n",
    "\n",
    "\n",
    "def calculate_returns_set(df, diffusion_map):\n",
    "    return (pd.DataFrame({factor: calculate_returns(df[factor], diffusion_map[factor]) \n",
    "                          for factor in df.columns\n",
    "                          })\n",
    "            .rename_axis(index='date', columns='factor_name'))\n",
    "    \n",
    "\n",
    "def accumulate_returns(ret, diffusion_type, level=None):\n",
    "    # TODO: This drops the first observation\n",
    "    if level is None:\n",
    "        level = ret.iloc[-1]\n",
    "    match diffusion_type:\n",
    "        case 'lognormal':\n",
    "            cret = ret.div(10_000).add(1).cumprod()\n",
    "            cret = cret / cret.iloc[-1] * level\n",
    "        case 'normal':\n",
    "            cret = ret.div(100).cumsum()\n",
    "            cret = cret - cret.iloc[-1] + level\n",
    "        case _:\n",
    "            raise ValueError(f'Unsupported diffusion_type of {diffusion_type} for {ret.name}')\n",
    "    return cret\n",
    "\n",
    "\n",
    "def accumulate_returns_set(ret, diffusion_map, level_map=None):\n",
    "    if level_map is None:\n",
    "        level_map = {factor: None for factor in ret.columns}  \n",
    "    return (pd.DataFrame({factor: accumulate_returns(ret[factor], diffusion_map[factor], level_map.get(factor, 100)) \n",
    "                          for factor in ret.columns\n",
    "                          })\n",
    "            .rename_axis(index='date', columns='factor_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_master = get_factor_master('factor_master.xlsx', 'read_new')\n",
    "factor_list = factor_master.index\n",
    "\n",
    "levels_raw = (get_yahoo_data_set(asset_names = factor_list, \n",
    "                                 tickers = factor_master.loc[factor_list, 'ticker'],\n",
    "                                 field_name = 'Adj Close'))\n",
    "levels = align_dates(levels_raw, ['SPX', 'USD10'])\n",
    "\n",
    "diffusion_map = factor_master['diffusion_type']\n",
    "levels_latest = levels.iloc[-1]\n",
    "\n",
    "ret = calculate_returns_set(levels, diffusion_map)\n",
    "cret = accumulate_returns_set(ret, diffusion_map, levels_latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_factor_data2(halflifes: List[int]) -> xr.Dataset:\n",
    "    # TODO: Check vol units\n",
    "    factor_master = get_factor_master('factor_master.xlsx', 'read')\n",
    "    factor_list = factor_master.index\n",
    "\n",
    "    factor_list_yf = factor_master.query('source==\"yfinance\"').index\n",
    "    levels_yf = (get_yahoo_data_set(asset_names = factor_list_yf.tolist(), \n",
    "                                     tickers = factor_master.loc[factor_list, 'ticker'],\n",
    "                                     field_name = 'Adj Close')\n",
    "                 .pipe(align_dates, ['SPY'])\n",
    "                 )\n",
    "\n",
    "    diffusion_map = factor_master['diffusion_type']\n",
    "    ret_yf = calculate_returns_set(levels_yf, diffusion_map)\n",
    "    \n",
    "    portfolios_weights = (get_portfolios()\n",
    "                          .pipe(safe_reindex, factor_master)\n",
    "                          .fillna(0)\n",
    "                          .loc[factor_list_yf]\n",
    "                          )\n",
    "    portfolios_ret = ret_yf @ portfolios_weights\n",
    "    levels_latest = levels_yf.iloc[-1]\n",
    "\n",
    "    factor_data = xr.Dataset()\n",
    "    factor_data['ret']  = pd.concat([ret_yf, portfolios_ret], axis=1).rename_axis(columns='factor_name')\n",
    "    factor_data['cret'] = accumulate_returns_set(factor_data['ret'].to_pandas(), diffusion_map, levels_latest)\n",
    "    factor_data['vol']  = get_volatility_set(factor_data['ret'], halflifes)\n",
    "    factor_data['corr'] = get_correlation_set(factor_data['ret'], halflifes)\n",
    "    factor_data['factor_name'].attrs = factor_master.T.to_dict()\n",
    "    \n",
    "    return factor_data #, diffusion_map, levels_latest\n",
    "\n",
    "halflifes = [21, 63, 121, 252]\n",
    "# factor_data, diffusion_map, levels_latest = build_factor_data2(halflifes)\n",
    "factor_data = build_factor_data2(halflifes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data.vol.sel(vol_type=63).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_factor_data_yf(halflifes: List[int]) -> xr.Dataset:\n",
    "    factor_master = get_factor_master('factor_master.xlsx', 'read_short')\n",
    "    factor_list = factor_master.index\n",
    "\n",
    "    levels_raw = (get_yahoo_data_set(asset_names = factor_list, \n",
    "                                     tickers = factor_master.loc[factor_list, 'ticker'],\n",
    "                                     field_name = 'Adj Close'))\n",
    "    levels = align_dates(levels_raw, ['SPX', 'USD10'])\n",
    "\n",
    "    diffusion_map = factor_master['diffusion_type']\n",
    "    levels_latest = levels.iloc[-1]\n",
    "\n",
    "    ret = calculate_returns_set(levels, diffusion_map)\n",
    "    cret = accumulate_returns_set(ret, diffusion_map, levels_latest)\n",
    "\n",
    "    factor_data = xr.Dataset\n",
    "    factor_data = xr.Dataset({'levels': levels.stack().to_xarray(), \n",
    "                              'ret':  ret.stack().to_xarray(), \n",
    "                              'cret': cret.stack().to_xarray()})\n",
    "    factor_data['vol']   = get_volatility_set(factor_data['ret'], halflifes)\n",
    "    factor_data['corr']  = get_correlation_set(factor_data['ret'], halflifes)\n",
    "    factor_data['factor_name'].attrs = factor_master.T.to_dict()\n",
    "    return factor_data\n",
    "\n",
    "halflifes = [21, 63, 121, 252]\n",
    "ds = build_factor_data2(halflifes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def regression_plot(df, x, y):\n",
    "    df = df[[x, y]].dropna()\n",
    "    X = df[x]\n",
    "    Y = df[y]\n",
    "    X = sm.add_constant(X)  # Adds a constant term to the predictor\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    # predictions = model.predict(X)\n",
    "\n",
    "    # Display the equation of the line\n",
    "    intercept, slope = model.params\n",
    "    print(f'Equation of line: Y = {intercept:.2f} + {slope:.2f}X')\n",
    "\n",
    "    # Create scatter plot with line of best fit\n",
    "    sns.lmplot(x=x, y=y, data=df)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "regression_plot(ret, 'USD10', 'TY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data(ticker, field_name, cache=None):\n",
    "    # TODO: Check cache first\n",
    "    return yf.download(ticker)[field_name]\n",
    "\n",
    "# cache = yf.download(factor_master['ticker'].iloc[:-1].to_list())\n",
    "\n",
    "lvl_raw_dict = {}\n",
    "for factor in factor_master.index:\n",
    "    lvl_raw_dict[factor] = get_yahoo_data(factor_master.loc[factor, 'ticker'], 'Adj Close')\n",
    "lvl_raw = pd.DataFrame(lvl_raw_dict)\n",
    "# TODO: Confirm outer join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_days = None\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_ffill(df, business_days, method=None, na_tolerance=None, diffusion_type=None):\n",
    "    # 1) Include business_days in df index\n",
    "    \n",
    "    if business_days is None:\n",
    "        full_dates = df.index.union(business_days)\n",
    "        df = df.reindex(full_dates)\n",
    "    # 2) Count consecutive NAs\n",
    "    # 3) Extract dates with NAs and their count (build replacement dataframe)\n",
    "    # 4) If consecutive NAs < na_tolerance, replacement data = 0 (for now) else nan\n",
    "    # 5) Forward fill\n",
    "    # 6) Add replacement (respecting diffusion_type)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_business_days(df, factors=['SPX']):\n",
    "    return df[factors].dropna(how='any').index\n",
    "\n",
    "\n",
    "def calculate_returns(levels, diffusion_type):\n",
    "    if diffusion_type == 'diff':\n",
    "        return levels.diff()\n",
    "    elif diffusion_type == 'pct':\n",
    "        return levels.pct_change()\n",
    "    else:\n",
    "        raise ValueError('diffusion_type must be either \"diff\" or \"pct\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ffill(lvl_raw, get_business_days(lvl_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a date range for the last three days\n",
    "data = [100, np.nan, np.nan, 101]\n",
    "date_range = pd.date_range(end=pd.Timestamp.today().date(), periods=len(data))\n",
    "\n",
    "\n",
    "# Create a dataframe with the specified values\n",
    "data = [100, np.nan, np.nan, 101]\n",
    "df = pd.Series(data, index=date_range) #, columns=['Value'])\n",
    "\n",
    "# pd.concat([df, df.pct_change()], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "asset_list = ['SPY', 'IWM', 'IEF', '^TNX', '^FCHI']\n",
    "diffusion_types = ['lognormal', 'lognormal', ]\n",
    "data = yf.download(asset_list)\n",
    "\n",
    "lvl = data['Adj Close']\n",
    "lvl.pipe(out)\n",
    "\n",
    "ret = lvl.pct_change().pipe(out)\n",
    "# Union any other data sources\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ffill(lvl_raw, get_business_days(lvl_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a date range for the last three days\n",
    "data = [100, np.nan, np.nan, 101]\n",
    "date_range = pd.date_range(end=pd.Timestamp.today().date(), periods=len(data))\n",
    "\n",
    "\n",
    "# Create a dataframe with the specified values\n",
    "data = [100, np.nan, np.nan, 101]\n",
    "df = pd.Series(data, index=date_range) #, columns=['Value'])\n",
    "\n",
    "# pd.concat([df, df.pct_change()], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "current_date = pd.Timestamp.today().date()\n",
    "print(current_date)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
