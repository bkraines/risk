{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf861065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from risk_data import get_factor_data\n",
    "from risk_chart import px_format\n",
    "from risk_event_study import draw_event_study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd271079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_window(\n",
    "    df: pd.Series | pd.DataFrame,\n",
    "    event_date: str | pd.Timestamp,\n",
    "    before: int = 21,\n",
    "    after: int = 63\n",
    ") -> pd.Series | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Select a window of rows from a date-indexed DataFrame around an event date.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with a DateTimeIndex, assumed sorted.\n",
    "    event_date : str | pd.Timestamp\n",
    "        The target event date.\n",
    "    before : int\n",
    "        Number of rows before the event date to include.\n",
    "    after : int\n",
    "        Number of rows after the event date to include.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Sliced DataFrame with [before rows] before and [after rows] after the next available event date.\n",
    "    \"\"\"\n",
    "    \n",
    "    event_date = pd.Timestamp(event_date)\n",
    "    # Find next available index position (bfill means â‰¥ event_date)\n",
    "    \n",
    "    event_idx = df.index.get_indexer([event_date], method='bfill')[0]\n",
    "    if event_idx == -1:\n",
    "        raise ValueError(f\"No date on or after {event_date} found in index!\")\n",
    "    \n",
    "    start_idx = max(event_idx - before, 0)\n",
    "    end_idx = event_idx + after + 1  # +1 because iloc is exclusive on end\n",
    "    return df.iloc[start_idx:end_idx]\n",
    "\n",
    "\n",
    "def run_event_study(returns_df: pd.Series | pd.DataFrame, \n",
    "                    event_list: list[tuple[str, pd.Timestamp]], \n",
    "                    before: int = 21, \n",
    "                    after:  int = 63) -> tuple:\n",
    "    \"\"\"\n",
    "    Perform event study using specific factor names tied to events.\n",
    "\n",
    "    Parameters:\n",
    "    - returns_df: pd.DataFrame (date index, return columns)\n",
    "    - event_list: list of (factor_name, event_date)\n",
    "    - before: days before event\n",
    "    - after: days after event\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # offsets = range(-before, after + 1)\n",
    "    # event_windows = []\n",
    "\n",
    "    _list = []\n",
    "    for factor_name, event_date in event_list:\n",
    "        _list.append(\n",
    "            get_event_window(returns_df[factor_name],\n",
    "                             event_date, \n",
    "                             before=before, \n",
    "                             after=after)\n",
    "            .rename('returns')\n",
    "            .to_frame()\n",
    "            # .assign(day_offset=range(-before, after + 1)) # THIS MIGHT BE TOO LONG\n",
    "            .assign(day_offset=lambda df_: range(-before, -before + len(df_)),\n",
    "                    factor_name=factor_name,\n",
    "                    event_date=event_date,\n",
    "                    cret = lambda df: df.groupby(['factor_name', 'event_date'])['returns'].cumsum(),\n",
    "                    )\n",
    "            .reset_index()\n",
    "            .set_index('day_offset')\n",
    "        )\n",
    "    return pd.concat(_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_study = run_event_study(ret, event_list, before=before, after=after)\n",
    "# event_study\n",
    "# px.line(event_study.reset_index(), x='day_offset', y='cret', color='event_date', template='plotly_white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f34956",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data = get_factor_data() #read_cache=False)\n",
    "ret = factor_data.ret.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7849f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = factor_data.ret.sel(factor_name=['^VIX'])\n",
    "df = df.to_pandas().div(10_000).add(1).cumprod().sub(1)\n",
    "px.line(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = factor_data.ret.sel(factor_name=['TRADEWAR'])\n",
    "px.line(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def flatten_multiindex(index, sep='_'):\n",
    "#     return index.map(lambda x: sep.join(map(str, x)))\n",
    "\n",
    "# def draw_event_study(ret, event_list, before, after):\n",
    "#     # TODO: Run cumulative return inside the event study\n",
    "#     event_study = run_event_study(ret, event_list, before=before, after=after)\n",
    "#     # event_study.reset_index().pivot(index='day_offset', columns=('factor_name', 'event_date'), values='returns')\n",
    "#     df_cum = event_study.reset_index().pivot(index='day_offset', columns=['factor_name', 'event_date'], values='returns').cumsum()\n",
    "#     df_cum.columns = flatten_multiindex(df_cum.columns, sep=';')\n",
    "\n",
    "#     # event_study -= event_study.loc[0]\n",
    "#     df_cum -= df_cum.loc[0]\n",
    "#     fig = px.line(df_cum/100, template='plotly_white', title='Event Study')\n",
    "#     return px_format(fig)\n",
    "\n",
    "    \n",
    "\n",
    "event_list_hispy = [('SPY', '2018-01-26'),  # Align SPY peak\n",
    "                   ('SPY', '2025-02-19'),]\n",
    "event_list_jan1 = [('^VIX', '2018-01-01'),  # Start Jan 1\n",
    "                   ('^VIX', '2025-01-01'),]\n",
    "event_list_hivix = [('^VIX', '2018-02-04'), # Align VIX peak\n",
    "                    ('^VIX', '2025-04-08')]\n",
    "event_list_hivix2 = [('^VIX', '2018-01-31'), # Align VIX peak, 1w prior (vix selloff)\n",
    "                     ('^VIX', '2025-04-01'),]\n",
    "event_list_hivix_spy = [('SPY', '2018-01-28'), # Align VIX peak 1w prior (SPY)\n",
    "                        ('SPY', '2025-04-01'),]\n",
    "event_list_hivix3 = [('SPY', '2018-01-24'), # Align first VIX selloff\n",
    "                     ('SPY', '2025-02-15'),]\n",
    "event_list_test = [('RSP', '2025-05-27'), ('IWM', '2025-05-09')]\n",
    "\n",
    "# TODO: Add election date\n",
    "# TODO: Fix composite portfolios\n",
    "# TODO: Add sharpe with rebalancing dates (returns on inverse-vol returns with rebalancing)\n",
    "# TODO: Add a level toggle that doesn't subtract the first value\n",
    "# TODO: Convert x-axis to date of first event\n",
    "# TODO: Ensure first (latest) event is on top\n",
    "\n",
    "event_list = event_list_hivix3\n",
    "before = 21*12\n",
    "after = 21*18\n",
    "factor_name, event_date = event_list[0]\n",
    "\n",
    "fig = draw_event_study(ret, event_list, before=before, after=after)\n",
    "# fig.update_yaxes(autorange='reversed')\n",
    "fig.show()\n",
    "# fig.reset_index() #.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f57000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_multiindex(index, sep='_'):\n",
    "    return index.map(lambda x: sep.join(map(str, x)))\n",
    "\n",
    "def test_event_study(ret, event_list, before, after):\n",
    "    # TODO: Run cumulative return inside the event study\n",
    "    event_study = run_event_study(ret, event_list, before=before, after=after)\n",
    "    # event_study.reset_index().pivot(index='day_offset', columns=('factor_name', 'event_date'), values='returns')\n",
    "    df_cum = event_study.reset_index().pivot(index='day_offset', columns=['factor_name', 'event_date'], values='returns').cumsum()\n",
    "    df_cum.columns = flatten_multiindex(df_cum.columns, sep=';')\n",
    "    # event_study -= event_study.loc[0]\n",
    "    df_cum -= df_cum.loc[0]\n",
    "    fig = px.line(df_cum/100, template='plotly_white', title='Event Study')\n",
    "    return px_format(fig)\n",
    "    # return df_cum\n",
    "\n",
    "ttt = test_event_study(ret, event_list=event_list_hispy, before=before, after=after)\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data.cret.sel(factor_name='^VIX').to_pandas().quantile([0, 0.15, 0.5, 0.85, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5d16e",
   "metadata": {},
   "source": [
    "# Where's the TRADEWAR bottleneck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d36329",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data.sel(factor_name='TRADEWAR').ret.dropna('date')\n",
    "\n",
    "factor_data.sel(factor_name=['FXF', 'FXY', 'GLD', 'XLP', 'XLY', '^VIX3M']).ret.to_pandas().dropna(how='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-bklm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
